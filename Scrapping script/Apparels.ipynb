{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Apparels.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF_SF-3G5llT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7ULvNOG5tpM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "998c3184-87b2-4ae9-9933-5ebf3116bd83"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT-mnKG_5u7J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f97adb17-06b5-4088-b3cf-ab0e008e69ba"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Flatten,Dense"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcU5yq-d61Xh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#implementing cnn\n",
        "model=Sequential()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2NWfvRi64RP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1st convolution layer\n",
        "model.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "#2nd Convolution layer\n",
        "model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "##rd Convolution layer\n",
        "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# The fourth convolution\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size =(2,2)))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcqnSX9T67I2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Flatten())"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMNrSLTq6-LF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  Full Connection\n",
        "model.add(Dense(units = 128, activation = 'relu'))\n",
        "model.add(Dense(units = 3, activation = 'softmax'))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY7BufOI7CgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compile\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o58SzcaX7HnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fitting the CNN to the images \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                  shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgEGgw6z7OVe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "aaa717e7-309c-40ed-e422-b00bb7d833d0"
      },
      "source": [
        "training_set = train_datagen.flow_from_directory('drive/My Drive/Neural Networks/CNN Apparels/training_set',\n",
        "                                                 target_size=(64,64),\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode='categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('drive/My Drive/Neural Networks/CNN Apparels/test_set',\n",
        "                                            target_size=(64,64),\n",
        "                                            batch_size=32,\n",
        "                                            class_mode='categorical')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 120 images belonging to 3 classes.\n",
            "Found 51 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1p6NI5z7SBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUgRoy4C8inU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "7bfab65e-7311-4044-9c16-5a96be643ed3"
      },
      "source": [
        "model.fit_generator(training_set,\n",
        "                        samples_per_epoch=120,\n",
        "                        nb_epoch=15,\n",
        "                        validation_data=test_set,\n",
        "                        nb_val_samples=51)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., steps_per_epoch=3, epochs=15, validation_steps=51)`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.8669 - accuracy: 0.5455 - val_loss: 0.8161 - val_accuracy: 0.5884\n",
            "Epoch 2/15\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.8730 - accuracy: 0.6250 - val_loss: 0.8992 - val_accuracy: 0.5873\n",
            "Epoch 3/15\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.7791 - accuracy: 0.5833 - val_loss: 0.7176 - val_accuracy: 0.5899\n",
            "Epoch 4/15\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.7410 - accuracy: 0.6818 - val_loss: 0.7014 - val_accuracy: 0.7643\n",
            "Epoch 5/15\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.7090 - accuracy: 0.7188 - val_loss: 0.7404 - val_accuracy: 0.6282\n",
            "Epoch 6/15\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.6649 - accuracy: 0.7250 - val_loss: 0.7287 - val_accuracy: 0.7040\n",
            "Epoch 7/15\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.5293 - accuracy: 0.8125 - val_loss: 0.5423 - val_accuracy: 0.7850\n",
            "Epoch 8/15\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.5399 - accuracy: 0.7841 - val_loss: 0.5859 - val_accuracy: 0.6283\n",
            "Epoch 9/15\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.4937 - accuracy: 0.7917 - val_loss: 0.4675 - val_accuracy: 0.8049\n",
            "Epoch 10/15\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.4606 - accuracy: 0.7955 - val_loss: 0.4642 - val_accuracy: 0.8223\n",
            "Epoch 11/15\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.4368 - accuracy: 0.8409 - val_loss: 0.6775 - val_accuracy: 0.5891\n",
            "Epoch 12/15\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.4369 - accuracy: 0.8182 - val_loss: 0.4979 - val_accuracy: 0.8037\n",
            "Epoch 13/15\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.4155 - accuracy: 0.8295 - val_loss: 0.5069 - val_accuracy: 0.8041\n",
            "Epoch 14/15\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.3542 - accuracy: 0.8854 - val_loss: 0.6507 - val_accuracy: 0.6059\n",
            "Epoch 15/15\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.4115 - accuracy: 0.8523 - val_loss: 0.4548 - val_accuracy: 0.8439\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f7158bcc240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlKtzv6r8lcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('drive/My Drive/Neural Networks/CNN Apparels/Prediction/img_14.jpeg', target_size=(64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = model.predict(test_image)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrmTXJOc_Kkt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5bc1fed8-6c99-4342-c584-2dc1feaba81d"
      },
      "source": [
        "result"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2z3ViOu_MK1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3b022f9-8f86-437d-b305-48cddfd5a978"
      },
      "source": [
        "training_set.class_indices\n",
        "if result[0][0] == 1: \n",
        "    print('saree')\n",
        "elif result[0][1] == 1:\n",
        "    print('shirt')\n",
        "else:\n",
        "  print('tshirt')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saree\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U93tWE0FAqav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}